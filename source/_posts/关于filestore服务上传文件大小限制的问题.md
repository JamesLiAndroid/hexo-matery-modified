---
title: 关于filestore服务上传文件大小限制的问题
top: false
cover: false
toc: true
mathjax: true
date: 2020-09-03 09:15:53
password:
summary:
tags:
categories:
---

# 关于filestore服务上传文件大小限制的问题

## 问题描述

2020年9月2日晚上，在前端服务推送到k8s以后，开始测试设备台账功能的文件上传操作，发现出现了Nginx 413错误，也就是**413 Request Entity Too Large*错误。不足1MB的文件可以正常上传，超过1MB的文件不能正常上传。根据官网和StackOverflow的建议，修复错误的方法很简单，在*server*节点下添加"*client_max_body_size 200m;*"，如下:

```

    server {
        listen       80;
        server_name  localhost;
        // 添加下面一句话解决问题
        client_max_body_size 200m;

```

## 所走弯路

当时所有小伙伴一致认为是fastdfs之前设定的nginx服务导致了这个错误，于是立刻开始修改该nginx的问题，测试了添加“*client_max_body_size 200m;*”配置信息的功能，但还是不成功。更换配置项所在位置也无法解决问题，例如将“*client_max_body_size 200m;*”放在*location*节点下，或者放在*http*节点下。根据fastdfs搭建文档中的描述，该nginx实际上承担的是获取文件链接，也就是文件下载的功能，文件上传走的还是fastdfs服务的22122端口，于是在这个位置排查并不正确。

## 正确的排查方式

对于微服务场景下，应该从全链路的角度来进行排查，首先梳理上传文件时涉及的服务信息，然后排查链路上涉及到的服务信息，最后查看所包含的nginx服务的点有几个，哪个影响了目前出现的结果。整个服务调用的链路信息如下：

前端服务-->gateway服务 --> filestore服务 --> fastdfs服务
                               |                  |
                               | ________<<<_____ |
                                      文件获取

在整个链路上首先怀疑的是filestore服务出现问题，导致文件上传不正确，于是将本地服务接入k8s中，进行调试，结果依旧是大于1MB的文件无法进行上传！

根据这个操作，排除对fastdfs前nginx服务的问题。

重新讨论这一部分的内容时，发现开发的同事在强调一个事情，开发环境和测试环境使用同一套fastdfs时，在开发环境运行正常。既然开发环境运行正常，也同样证明了fastdfs前nginx服务不存在问题。

那么后续就是，整条链路上到底有几个nginx服务？列举如下：

- 前端服务，由nginx承载
- fastdfs之前的nginx服务
- k8s中ingress功能由nginx实现

之前的调试证明了fastdfs之前的nginx服务不存在问题，下一步看k8s中的ingress，由于目前所有的服务均使用nodePort模式对外暴露访问地址，并未使用ingress服务对外暴露服务地址，所以也排除这个信息。

那最后只剩下前端服务所在的nginx了，尝试去k8s中找到对应的psl前端服务所在的容器，修改容器中的配置文件，但是修改完成并没找到重新加载的方式。因此，在最早的一台服务器上（192.168.66.200），使用之前搭建的nginx进行测试。修改nginx.conf配置文件，添加“*client_max_body_size 200m;*”配置信息，然后重新打包psl前端项目并上传到服务器，进行测试，发现15MB的一个PPT文件是可以传上去的！

那这里就是问题所在了，前端镜像存在问题，再准确点说前端基础镜像存在问题，于是这里修改了前端基础镜像，添加“*client_max_body_size 200m;*”配置信息，最后部署到k8s中，问题解决！

## 经验与教训

1. 对于微服务体系下的问题排查，一定要做到全链路考虑，前后端结合
2. 尽早排除链路上不相关的内容
3. 对每一个服务的走向和链路信息要十分熟悉才能尽可能快的排查！
